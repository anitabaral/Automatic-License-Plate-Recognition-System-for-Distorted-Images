{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recognition.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMtMXWr4cr_M"
      },
      "source": [
        "####**Optical Character Recognition using SVM**\n",
        "Training svm model on characters of gandaki zone obtained after segmentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZWwA7DfdQQt"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from skimage.io import imread\n",
        "from skimage.filters import threshold_otsu\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-ujJrdSdi7h"
      },
      "source": [
        "def preprocessing(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    image = cv2.resize(img,(40, 40), interpolation = cv2.INTER_AREA )\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # converts each character image to binary image\n",
        "    binary_image = cv2.threshold(gray, 180, 255,\n",
        "    cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
        "    # the 2D array of each image is flattened because the machine learning\n",
        "    # classifier requires that each sample is a 1D array\n",
        "    # therefore the 20*20 image becomes 1*400\n",
        "    # in machine learning terms that's 400 features with each pixel\n",
        "    # representing a feature\n",
        "    flat_bin_image = binary_image.reshape(-1)\n",
        "\n",
        "    return flat_bin_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvhKQihDMxOZ"
      },
      "source": [
        "Loading the segmented characters dataset and then training the SVM on that dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWt0e88iduBE"
      },
      "source": [
        "letters = [\n",
        "            '०', '१', '२', '३', '४', '५', '६', '७', '८', '९', 'ग', 'प'\n",
        "        ]\n",
        "\n",
        "def read_training_data(training_directory):\n",
        "    image_data = []\n",
        "    target_data = []\n",
        "    for each_letter in letters:\n",
        "        path = os.path.join(training_directory, each_letter,'*' + '.jpg')\n",
        "        image_paths = glob.glob(path)\n",
        "        for each in range(len(image_paths)):\n",
        "            image_path = os.path.join(training_directory, each_letter, str(each) + '.jpg')\n",
        "            flat_bin_image = preprocessing(image_path)\n",
        "            image_data.append(flat_bin_image)\n",
        "            target_data.append(each_letter)\n",
        "            \n",
        "    return (np.array(image_data), np.array(target_data))\n",
        "\n",
        "\n",
        "\n",
        "current_dir = '/content/drive/MyDrive/Colab Notebooks/ALPR/SISR/ALPR_Distorted/'\n",
        "\n",
        "training_dataset_dir = '/content/drive/MyDrive/Colab Notebooks/ALPR/SISR/ALPR_Distorted/segmented_dataset_organized'\n",
        "\n",
        "image_data, target_data = read_training_data(training_dataset_dir)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(image_data, target_data, random_state = 0, test_size = 0.25)\n",
        "\n",
        "classifier_predictions = svc_model.predict(x_test)\n",
        "print(accuracy_score(y_test, classifier_predictions) * 100)\n",
        "\n",
        "matrix = confusion_matrix(y_test, classifier_predictions, labels = ['०', '१', '२', '३', '४', '५', '६', '७', '८', '९', 'ग', 'प'])\n",
        "print('Confusion matrix : \\n ', matrix)\n",
        "\n",
        "'''we will use the joblib module to persist the model\n",
        "into files. This means that the next time we need to\n",
        "predict, we don't need to train the model again'''\n",
        "\n",
        "#This part of the code is used for saving the model after training it in the required dataset\n",
        "\n",
        "save_directory = os.path.join(current_dir, 'models/svc/')\n",
        "if not os.path.exists(save_directory):\n",
        "    os.makedirs(save_directory)\n",
        "joblib.dump(svc_model, save_directory+'/svc.pkl')\n",
        "\n",
        "print(accuracy_score(y_test, classifier_predictions) * 100)\n",
        "print(f1_score(y_test, classifier_predictions, average='macro') * 100)\n",
        "print(recall_score(y_test, classifier_predictions, average='macro') * 100)\n",
        "print(precision_score(y_test, classifier_predictions, average='macro') * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHZUe7uLe5N0"
      },
      "source": [
        "def cross_validation(model, num_of_fold, train_data, train_label):\n",
        "    ''' this uses the concept of cross validation to measure the accuracy of a model, the num_of_fold determines the type of validation\n",
        "    e.g if num_of_fold is 4, then we are performing a 4-fold cross validation it will divide the dataset into 4 and use 1/4 of it for testing\n",
        "    and the remaining 3/4 for the training'''\n",
        "\n",
        "    accuracy_result = cross_val_score(model, train_data, train_label,\n",
        "                                      cv=num_of_fold)\n",
        "    print(\"Cross Validation Result for \", str(num_of_fold), \" -fold\")\n",
        "\n",
        "    print(accuracy_result * 100)\n",
        "\n",
        "cross_validation(svc_model, 4, image_data, target_data)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}